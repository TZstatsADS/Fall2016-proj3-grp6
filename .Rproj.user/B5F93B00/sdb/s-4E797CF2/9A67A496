{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Image recognition | Chicken or Dog?\"\nauthor: \"Team 6\"\noutput:\n  html_notebook: default\n  html_document: default\n---\n\n\n```{r setup, include=FALSE}\nrm(list = ls())\n\n# Install missing packages\nlist.of.packages <- c(\"lfda\", \"plotly\", \"MASS\", \"matrixStats\", \"caret\", \"e1071\")\nnew.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])]\nif(length(new.packages)) install.packages(new.packages)\n\nlibrary(lfda)\nlibrary(plotly)\nlibrary(MASS)\nlibrary(matrixStats)\nlibrary(caret)\nlibrary(e1071)\n\nknitr::opts_chunk$set(echo = TRUE, fig.width = 12)\n#knitr::opts_chunk$set(out.width='750px', dpi=200)\n\n### Specify directories\nsetwd(dirname(rstudioapi::getActiveDocumentContext()$path))\n```\n\n```{r, echo=FALSE}\n\nimg_train_dir <- \"./data/images/\"\nnum.chicken <- 1000\nnum.dog <- 1000\nlabel.train <- c(rep(0, num.chicken), rep(1, num.dog))\nlabel.train <- as.data.frame(label.train)\nnames(label.train) <- c(\"val\")\nlabel.train$val <- as.factor(label.train$val)\n\n### Construct visual feature ----\nsource(\"./lib/feature.R\")\ntm_feature_train <- system.time(dat.train <- feature.base(\"sift_features.csv\"))\n# Columns are images. Rows are SIFT features. Got to transpose.\n```\n\n## 1. Principal Component Analycis (PCA) \n### to reduce dimensionality of SIFT features\n```{r, echo=FALSE}\n# PCA\n\nsift.pca <- prcomp(dat.train)\n?prcomp\nplot(cumsum(sift.pca$sdev)/sum(sift.pca$sdev),\n     main =\"Cumulative variance captured | PCA over SIFT features\",\n     sub = paste(\"Total features = \", ncol(dat.train), \", Total Images = \", nrow(dat.train)), \n     xlab = \"# of Components\",\n     ylab = \"% of Variance\")\n```\n<br>\n**PCA does not seem to help reducing the dimensionality of the problem. Poor correlation between features.**\n\n----\n### 2. LFDA Fisher discriminant analysis. Plotting FD1 vs FD2\n```{r, echo=FALSE, out.width=12, fig.align=\"center\", fig.width=12}\n\nfda.model <- lfda(x = dat.train[,1:1900], y = label.train$val, r = 1900, metric=\"plain\")\n\nZ <- as.data.frame(fda.model$Z)\n#names(Z) <- c(1:1900)\n\nplot_ly(data = Z, x = Z[,1]*100000, y = Z[,2]*100000, color = label.train$val,\n        text = rownames(Z), mode=\"markers\" )%>%\n  layout(title = \"Fisher Discriminant Analyis, taking only first 1900 columns\")\n\n\n```\n<br>\n**We seem to have a lead here. Linear separation between classes.**\n\n```{r, echo=FALSE, out.width=12, fig.align=\"center\", fig.width=12}\nlowVariance <- nearZeroVar(dat.train)\ndat.train.variance <- dat.train[,-lowVariance]\ngood.variance.ncol <- ncol(dat.train.variance)\nnumcol.to.use <- min(good.variance.ncol, nrow(dat.train.variance))-100\n\n\nfda.model <- lfda(x = dat.train[,1:numcol.to.use], y = label.train$val, r = numcol.to.use, metric=\"plain\")\nZ <- as.data.frame(fda.model$Z)\n\np <- plot_ly(data = Z, x = Z[,1]*100000, y = Z[,2]*100000, color = label.train$val,\n        text = rownames(Z), mode=\"markers\" ) %>%\n  layout(title = \"Fisher Discriminant Analyis, taking first 2000 columns, filtered low variance\")\np\n\n```\n\n### 3. Trying Reduced Rank Fisher Discriminant Analysis\n```{r, echo=FALSE}\n\ndat.train.variance.labeled <- cbind(dat.train.variance[,1:numcol.to.use], label.train)\n\n\nlda.model <- lda(formula = val ~ .,\n                 data = dat.train.variance.labeled,\n                 CV = TRUE)\n\nlda.model.table <- table(dat.train.variance.labeled$val, lda.model$class)\nconCV1 <- rbind(lda.model.table[1, ]/sum(lda.model.table[1, ]), lda.model.table[2, ]/sum(lda.model.table[2, ]))\ndimnames(conCV1) <- list(Actual = c(\"No\", \"Yes\"), \"Predicted (cv)\" = c(\"No\",\"Yes\"))\nprint(round(conCV1, 3))\n\n```\n\n<br>\n**Running LDA over the training data does not seem to work properly. But the reduced rank dimension looks good. Can I do something over that?**\n\n### 4. SVM Plain vanilla\nError levels of the 10-fold cross validation\n```{r, echo=FALSE}\nsvm.model <- svm(val ~ ., \n                 data = dat.train.variance.labeled,\n                 cross = 10)\n\nsvm.model$accuracies\n\n```\n\n\n### 5. SVM over the FDA\nError levels of the 10-fold cross validation\n```{r, echo=FALSE}\nz.labeled <- cbind(Z, label.train)\n\nsvm.model <- svm(val ~ ., \n                 data = z.labeled,\n                 cross = 10)\n\nsvm.model$accuracies\n\n```\n\n### 6. SVM over the FDA with just 2 fisher features \nError levels of the 10-fold cross validation\n```{r, echo=FALSE}\nz.labeled.fewCols <- cbind(Z[,1:2], label.train)\n\nsvm.model <- svm(val ~ ., \n                 data = z.labeled.fewCols,\n                 cross = 10)\n\nsvm.model$accuracies\n\n```\n\n\n### Exploring RGB channels\n```{r, echo=FALSE}\n\nlibrary(EBImage)\nlibrary(fitdistrplus)\nlibrary(mixtools)\n\ndog.file <- \"dog_1000.jpg\"\nchicken.file <- \"chicken_0001.jpg\"\n\nimg.dog <- readImage(paste0(\"./data/images/\",dog.file))\nimg.chicken <- readImage(paste0(\"./data/images/\",chicken.file))\n\n\nhist(img.chicken, main = chicken.file)\nhist(img.dog, main = dog.file)\n\n```\n\n### The red channel of chicken\n```{r}\nred.channel <- as.vector(as.array(img.chicken[,,1]))\nhist(red.channel)\n```\n\n### Fitting a Gaussian to the Red Channel\n```{r}\nfitted.dist <- fitdist(red.channel, \"norm\", \"mle\")\nplot(fitted.dist)\n```\n\n\n\n### Fitting a mix of Gaussians using the EM algorithm\n```{r}\nfitted.dist.mix <- normalmixEM2comp(red.channel, mu = c(0.25, 0.75), lambda = 0.2, sigsqrd = c(1,0.5),\n                                    maxit = 50)\n\n\np <- plot(fitted.dist.mix, whichplots = 2)\n```\nThis seems to be better\n\n```{r}\nfitted.dist.mix <- normalmixEM2comp(red.channel, mu = c(0.25, 0.75), lambda = 0.2, sigsqrd = c(1,0.5),\n                                    maxit = 100)\n\n\np <- plot(fitted.dist.mix, whichplots = 2)\n```\n\n```{r}\nfitted.dist.mix <- normalmixEM2comp(red.channel, mu = c(0.25, 0.75), lambda = 0.2, sigsqrd = c(1,0.5),\n                                    maxit = 150)\n\n\np <- plot(fitted.dist.mix, whichplots = 2)\n```\n\n\n\n```{r}\n\nfile <- \"dog_0997.jpg\"\nimg.file <- readImage(paste0(\"./data/images/\",file))\n\nfor(i in 1:3){\n  channel <- as.vector(as.array(img.file[,,i]))\n  channel <- channel[channel < 0.95]\n  hist(channel)\n}\n\n\n\n```\n\n",
    "created" : 1477840306246.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1108538761",
    "id" : "9A67A496",
    "lastKnownWriteTime" : 1477858706,
    "last_content_update" : 1477871724240,
    "path" : "C:/Users/jgaci/Google Drive/2016_Fall/Applied_Data_Science/Project03/Fall2016-proj3-grp6/Exploring_Methods.Rmd",
    "project_path" : "Exploring_Methods.Rmd",
    "properties" : {
        "chunk_output_type" : "inline",
        "last_setup_crc32" : "BC44D65Bb49b0a00"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}