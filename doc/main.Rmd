---
title: "Image recognition | Chicken or Dog?"
author: "Team 6"
#date: "October 17, 2016"
output: 
  html_notebook: default
---


```{r setup, include=FALSE}
install.packages("ggfortify")
install.packages("lfda")
install.packages("matrixStats")


library(ggfortify)
library(lfda)
library(plotly)
library(MASS)
library(matrixStats)


setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_chunk$set(out.width='750px', dpi=200)

### Specify directories
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

img_train_dir <- "./data/images/"
num_chicken <- 1000
num_dog <- 1000
label_train <- c(rep(0, num_chicken), rep(1, num_dog))

### Construct visual feature ----
source("./lib/feature.R")
tm_feature_train <- system.time(dat_train <- feature_base("sift_features.csv"))
# Columns are images. Rows are SIFT features. Got to transpose.
```

## 1. Principal Component Analycis (PCA) 
### to reduce dimensionality of SIFT features
```{r, echo=FALSE}
# PCA

sift.pca <- prcomp(dat_train)
?prcomp
plot(cumsum(sift.pca$sdev)/sum(sift.pca$sdev),
     main ="Cumulative variance captured | PCA over SIFT features",
     sub = paste("Total features = ", ncol(dat_train), ", Total Images = ", nrow(dat_train)), 
     xlab = "# of Components",
     ylab = "% of Variance")
```
<br>
**PCA does not seem to help reducing the dimensionality of the problem. Poor correlation between features.**

----
### 2. LFDA Fisher discriminant analysis. Plotting FD1 vs FD2
```{r, echo=FALSE}
label.train <- as.data.frame(label_train)
names(label.train) <- c("val")
label.train$val <- as.factor(label.train$val)

fda.model <- lfda(x = dat_train[,1:1900], y = label.train$val, r = 1900, metric="plain")
#autoplot(fda.model, data = label.train, frame = TRUE, frame.colour = "val")
Z <- as.data.frame(fda.model$Z)
names(Z) <- c(1:1900)
plot_ly(data = Z, x = Z[,1]*100000, y = Z[,2]*100000, color = label.train$val, mode="markers" ) 

```
<br>
**We seem to have a lead here. Linear separation between classes.**

```{r, echo=FALSE}
dat.train.labeled <- cbind(dat_train[,1:1900], label.train)

names(dat.train.labeled)[1500:1901]

lda.model <- lda(formula = val ~ .,
                 data = dat.train.labeled)

## Filter the first decile of lowest variances
variance.train.labeled <- colVars(as.matrix(dat.train.labeled[,1:1900]))
variance.train.labeled <- as.data.frame(variance.train.labeled)
variance.train.labeled.first.decile <- quantile(variance.train.labeled$variance.train.labeled, probs = .1)
variance.train.labeled$cutlow <- variance.train.labeled[,1] <= variance.train.labeled.first.decile

## Variables seem constant. Calculate variance. Filter low variance (ones who dont change).  Re Run.
## Create LDA with the variables that are not filtered. Re run. Should work now!
```

