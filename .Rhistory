label.train$val <- factor(label.train$val)
### Construct visual feature ----
source("./lib/feature.R")
tm_feature_train <- system.time(dat.train <- feature.JG("sift_features.csv"))
# Columns are images. Rows are SIFT features. Got to transpose.
#----
# Randomize the order of the input data
## 1. Merge data and labels
dat.train.labeled <- cbind(dat.train, label.train)
## 2. Randomize
dat.train.labeled <- dat.train.labeled[sample(1:nrow(dat.train.labeled)),]
## 3. Separate them
dat.train <- dat.train.labeled[,1:ncol(dat.train)]
label.train.use <- dat.train.labeled$val
save(dat.train, file="./output/feature_train.RData")
### Train a classification model with training images
source("./lib/train.R")
source("./lib/test.R")
### Model selection with cross-validation ----
# Choosing between different values of interaction depth for GBM
source("./lib/cross_validation.R")
#depth_values <- seq(3, 11, 2)
params <- list(c("linear", 1, 2)
,c("linear", 1, 5)
,c("linear", 1, 10)
,c("linear", 1, 15)
)
ntests <- length(params)
err_cv <- array(dim=c(length(kernels), 2))
K <- 10  # number of CV folds
for(k in 1:length(params)){
cat("== kernel =", param[[k]][1], " degree = ", param[[k]][2], "dim = ", param[[k]][3], "== \n")
err_cv[k,] <- cv.function(dat.train, label.train.use, params[k], K)
}
save(err_cv, file="./output/err_cv.RData")
# Visualize CV results
jpeg(file = "./figs/cv_results.jpg")
plot(x = 1:ntests, y = err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
points(1:ntests, err_cv[,1], col="blue", pch=16)
lines(1:ntests, err_cv[,1], col="blue")
arrows(1:ntests, err_cv[,1]-err_cv[,2],1:ntests, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
dev.off()
# Choose the best parameter value
#depth_best <- depth_values[which.min(err_cv[,1])]
#par_best <- list(depth=depth_best)
# train the model with the entire training set
#tm_train <- system.time(fit_train <- train(dat.train, label.train, par_best))
#save(fit_train, file="./output/fit_train.RData")
### Make prediction
#tm_test <- system.time(pred_test <- test(fit_train, dat_test))
#save(pred_test, file="./output/pred_test.RData")
### Summarize Running Time
#cat("Time for constructing training features=", tm_feature_train[1], "s \n")
#cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
#cat("Time for training model=", tm_train[1], "s \n")
#cat("Time for making prediction=", tm_test[1], "s \n")
#############################################
### Main execution script for experiments ###
#############################################
### Author: Jaime Gacitua (credits to Yuting Ma)
### Project 3
### ADS Spring 2016
rm(list = ls())
# Install missing packages
list.of.packages <- c("lfda", "plotly", "MASS", "matrixStats", "caret", "e1071")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(lfda)
library(plotly)
library(MASS)
library(matrixStats)
library(caret)
library(e1071)
### Specify directories
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
img_train_dir <- "./data/images/"
#img_test_dir <- "./data/zipcode_test/"
### Import training images class labels ----
#label_train <- read.table("./data/zip_train_label.txt", header=F)
#label_train <- as.numeric(unlist(label_train) == "9")
num.chicken <- 1000
num.dog <- 1000
label.train <- c(rep(0, num.chicken), rep(1, num.dog))
label.train <- as.data.frame(label.train)
names(label.train) <- c("val")
label.train$val <- factor(label.train$val)
### Construct visual feature ----
source("./lib/feature.R")
tm_feature_train <- system.time(dat.train <- feature.JG("sift_features.csv"))
# Columns are images. Rows are SIFT features. Got to transpose.
#----
# Randomize the order of the input data
## 1. Merge data and labels
dat.train.labeled <- cbind(dat.train, label.train)
## 2. Randomize
dat.train.labeled <- dat.train.labeled[sample(1:nrow(dat.train.labeled)),]
## 3. Separate them
dat.train <- dat.train.labeled[,1:ncol(dat.train)]
label.train.use <- dat.train.labeled$val
save(dat.train, file="./output/feature_train.RData")
### Train a classification model with training images
source("./lib/train.R")
source("./lib/test.R")
### Model selection with cross-validation ----
# Choosing between different values of interaction depth for GBM
source("./lib/cross_validation.R")
#depth_values <- seq(3, 11, 2)
params <- list(c("linear", 1, 2)
,c("linear", 1, 5)
,c("linear", 1, 10)
,c("linear", 1, 15)
)
ntests <- length(params)
err_cv <- array(dim=c(length(params), 2))
K <- 10  # number of CV folds
for(k in 1:length(params)){
cat("== kernel =", params[[k]][1], " degree = ", params[[k]][2], "dim = ", params[[k]][3], "== \n")
err_cv[k,] <- cv.function(dat.train, label.train.use, params[k], K)
}
save(err_cv, file="./output/err_cv.RData")
# Visualize CV results
jpeg(file = "./figs/cv_results.jpg")
plot(x = 1:ntests, y = err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
points(1:ntests, err_cv[,1], col="blue", pch=16)
lines(1:ntests, err_cv[,1], col="blue")
arrows(1:ntests, err_cv[,1]-err_cv[,2],1:ntests, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
dev.off()
#############################################
### Main execution script for experiments ###
#############################################
### Author: Jaime Gacitua (credits to Yuting Ma)
### Project 3
### ADS Spring 2016
rm(list = ls())
# Install missing packages
list.of.packages <- c("lfda", "plotly", "MASS", "matrixStats", "caret", "e1071")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(lfda)
library(plotly)
library(MASS)
library(matrixStats)
library(caret)
library(e1071)
### Specify directories
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
img_train_dir <- "./data/images/"
#img_test_dir <- "./data/zipcode_test/"
### Import training images class labels ----
#label_train <- read.table("./data/zip_train_label.txt", header=F)
#label_train <- as.numeric(unlist(label_train) == "9")
num.chicken <- 1000
num.dog <- 1000
label.train <- c(rep(0, num.chicken), rep(1, num.dog))
label.train <- as.data.frame(label.train)
names(label.train) <- c("val")
label.train$val <- factor(label.train$val)
### Construct visual feature ----
source("./lib/feature.R")
tm_feature_train <- system.time(dat.train <- feature.JG("sift_features.csv"))
# Columns are images. Rows are SIFT features. Got to transpose.
#----
# Randomize the order of the input data
## 1. Merge data and labels
dat.train.labeled <- cbind(dat.train, label.train)
## 2. Randomize
dat.train.labeled <- dat.train.labeled[sample(1:nrow(dat.train.labeled)),]
## 3. Separate them
dat.train <- dat.train.labeled[,1:ncol(dat.train)]
label.train.use <- dat.train.labeled$val
save(dat.train, file="./output/feature_train.RData")
### Train a classification model with training images
source("./lib/train.R")
source("./lib/test.R")
### Model selection with cross-validation ----
# Choosing between different values of interaction depth for GBM
source("./lib/cross_validation.R")
#depth_values <- seq(3, 11, 2)
params <- list(c("linear", 1, 2)
,c("linear", 1, 5)
,c("linear", 1, 10)
,c("linear", 1, 15)
)
ntests <- length(params)
err_cv <- array(dim=c(length(params), 2))
K <- 10  # number of CV folds
for(k in 1:length(params)){
cat("== kernel: ", params[[k]][1], " degree: ", params[[k]][2], "dimZ: ", params[[k]][3], "== \n")
err_cv[k,] <- cv.function(dat.train, label.train.use, params[k], K)
}
save(err_cv, file="./output/err_cv.RData")
# Visualize CV results
jpeg(file = "./figs/cv_results.jpg")
plot(x = 1:ntests, y = err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
points(1:ntests, err_cv[,1], col="blue", pch=16)
lines(1:ntests, err_cv[,1], col="blue")
arrows(1:ntests, err_cv[,1]-err_cv[,2],1:ntests, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
dev.off()
# Choose the best parameter value
#depth_best <- depth_values[which.min(err_cv[,1])]
#par_best <- list(depth=depth_best)
# train the model with the entire training set
#tm_train <- system.time(fit_train <- train(dat.train, label.train, par_best))
#save(fit_train, file="./output/fit_train.RData")
### Make prediction
#tm_test <- system.time(pred_test <- test(fit_train, dat_test))
#save(pred_test, file="./output/pred_test.RData")
### Summarize Running Time
#cat("Time for constructing training features=", tm_feature_train[1], "s \n")
#cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
#cat("Time for training model=", tm_train[1], "s \n")
#cat("Time for making prediction=", tm_test[1], "s \n")
jpeg(file = "./figs/cv_results.jpg")
plot(x = 1:ntests, y = err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
points(1:ntests, err_cv[,1], col="blue", pch=16)
jpeg(file = "./figs/cv_results.jpg")
plot(x = 1:ntests, y = err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
points(1:ntests, err_cv[,1], col="blue", pch=16)
lines(1:ntests, err_cv[,1], col="blue")
arrows(1:ntests, err_cv[,1]-err_cv[,2],1:ntests, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
View(err_cv)
jpeg(file = "./figs/cv_results.jpg")
plot(x = 1:ntests, y = err_cv[,1], xlab="Interaction Depth", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
plot(x = 1:ntests, y = err_cv[,1], xlab="Parameter Tuning #", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
points(1:ntests, err_cv[,1], col="blue", pch=16)
lines(1:ntests, err_cv[,1], col="blue")
arrows(1:ntests, err_cv[,1]-err_cv[,2],1:ntests, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
jpeg(file = "./figs/cv_results.jpg")
plot(x = 1:ntests, y = err_cv[,1], xlab="Parameter Tuning #", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
points(1:ntests, err_cv[,1], col="blue", pch=16)
lines(1:ntests, err_cv[,1], col="blue")
arrows(1:ntests, err_cv[,1]-err_cv[,2],1:ntests, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
dev.off(which = 1)
dev.off(which = 0)
jpeg(file = "./figs/cv_results.jpg")
plot(x = 1:ntests, y = err_cv[,1], xlab="Parameter Tuning #", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
dev.off(which = 2)
jpeg(file = "./figs/cv_results.jpg")
plot(x = 1:ntests, y = err_cv[,1], xlab="Parameter Tuning #", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
points(1:ntests, err_cv[,1], col="blue", pch=16)
lines(1:ntests, err_cv[,1], col="blue")
arrows(1:ntests, err_cv[,1]-err_cv[,2],1:ntests, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
dev.off(which = dev.cur())
dev.off(which = dev.cur())
dev.off(which = dev.cur())
dev.off(which = dev.cur())
dev.off(which = dev.cur())
dev.off(which = dev.cur())
jpeg(file = "./figs/cv_results.jpg")
dev.off(which = dev.cur())
plot(x = 1:ntests, y = err_cv[,1], xlab="Parameter Tuning #", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
points(1:ntests, err_cv[,1], col="blue", pch=16)
lines(1:ntests, err_cv[,1], col="blue")
arrows(1:ntests, err_cv[,1]-err_cv[,2],1:ntests, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
jpeg(file = "./figs/cv_results.jpg")
plot(x = 1:ntests, y = err_cv[,1], xlab="Parameter Tuning #", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
points(1:ntests, err_cv[,1], col="blue", pch=16)
lines(1:ntests, err_cv[,1], col="blue")
arrows(1:ntests, err_cv[,1]-err_cv[,2],1:ntests, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
dev.off()
plot(x = 1:ntests, y = err_cv[,1], xlab="Parameter Tuning #", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
points(1:ntests, err_cv[,1], col="blue", pch=16)
lines(1:ntests, err_cv[,1], col="blue")
arrows(1:ntests, err_cv[,1]-err_cv[,2],1:ntests, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
plot(x = 1:ntests, y = err_cv[,1], xlab="Parameter Tuning #", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
plot(x = 1:ntests, y = err_cv[,1], xlab="Parameter Tuning #", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
points(1:ntests, err_cv[,1], col="blue", pch=16)
lines(1:ntests, err_cv[,1], col="blue")
arrows(1:ntests, err_cv[,1]-err_cv[,2],1:ntests, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
jpeg(file = "./figs/cv_results_zDimensions.jpg")
plot(x = 1:ntests, y = err_cv[,1], xlab="Parameter Tuning #", ylab="CV Error",
main="Cross Validation Error", ylim=c(0, 1))
lines(1:ntests, err_cv[,1], col="blue")
points(1:ntests, err_cv[,1], col="blue", pch=16)
dev.off()
arrows(1:ntests, err_cv[,1]-err_cv[,2],1:ntests, err_cv[,1]+err_cv[,2],
length=0.1, angle=90, code=3)
library(EBImage)
library(fitdistrplus)
library(mixtools)
img.dog <- readImage("./data/images/dog_1000.jpg")
img.chicken <- readImage("./data/images/chicken_0001.jpg")
hist(img.chicken)
red.channel <- as.vector(as.array(img.chicken[,,1]))
hist(red.channel)
fitted.dist <- fitdist(red.channel, "norm", "mle")
plot(fitted.dist)
fitted.dist.mix <- normalmixEM2comp(red.channel, mu = c(0.25, 0.75), lambda = 0.2, sigsqrd = c(1,0.5),
maxit = 100)
p <- plot(fitted.dist.mix, whichplots = 2)
p
library(EBImage)
library(fitdistrplus)
library(mixtools)
dog.file <- "dog_1000.jpg"
chicken.file <- "chicken_0001.jpg"
img.dog <- readImage(paste0("./data/images/",dog.file))
img.chicken <- readImage(paste0("./data/images/",chicken.file))
hist(img.chicken, title(main = chicken.file))
hist(img.chicken)
title(main = chicken.file)
hist(img.chicken) %>% title(main = chicken.file)
hist(img.chicken) %>%
title(main = chicken.file)
hist(img.chicken)
hist(img.chicken, title = chicken.file)
hist(img.chicken, main = chicken.file)
hist(img.dog, main = dog.file)
library(EBImage)
library(fitdistrplus)
library(mixtools)
dog.file <- "dog_1000.jpg"
chicken.file <- "chicken_0001.jpg"
img.dog <- readImage(paste0("./data/images/",dog.file))
img.chicken <- readImage(paste0("./data/images/",chicken.file))
hist(img.chicken, main = chicken.file)
hist(img.dog, main = dog.file)
fitted.dist.mix <- normalmixEM2comp(red.channel, mu = c(0.25, 0.75), lambda = 0.2, sigsqrd = c(1,0.5),
maxit = 50)
p <- plot(fitted.dist.mix, whichplots = 2)
fitted.dist.mix <- normalmixEM2comp(red.channel, mu = c(0.25, 0.75), lambda = 0.2, sigsqrd = c(1,0.5),
maxit = 100)
p <- plot(fitted.dist.mix, whichplots = 2)
fitted.dist.mix <- normalmixEM2comp(red.channel, mu = c(0.25, 0.75), lambda = 0.2, sigsqrd = c(1,0.5),
maxit = 150)
p <- plot(fitted.dist.mix, whichplots = 2)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
img_train_dir <- "./data/images/"
#img_test_dir <- "./data/zipcode_test/"
### Import training images class labels ----
#label_train <- read.table("./data/zip_train_label.txt", header=F)
#label_train <- as.numeric(unlist(label_train) == "9")
num_chicken <- 1000
num_dog <- 1000
label_train <- c(rep(0, num_chicken), rep(1, num_dog))
### Construct visual feature ----
source("./lib/feature.R")
tm_feature_train <- system.time(dat_train <- feature_base("sift_features.csv"))
# Columns are images. Rows are SIFT features. Got to transpose.
#############################################
### Main execution script for experiments ###
#############################################
### Author: Yuting Ma
### Project 3
### ADS Spring 2016
### Specify directories
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
img_train_dir <- "./data/images/"
#img_test_dir <- "./data/zipcode_test/"
### Import training images class labels ----
#label_train <- read.table("./data/zip_train_label.txt", header=F)
#label_train <- as.numeric(unlist(label_train) == "9")
num_chicken <- 1000
num_dog <- 1000
label_train <- c(rep(0, num_chicken), rep(1, num_dog))
### Construct visual feature ----
source("./lib/feature.R")
tm_feature_train <- system.time(dat_train <- feature_base("sift_features.csv"))
tm_feature_train_RGB < system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
dat_train_RGB <- feature_RGB("./data/images/", "RGB")
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
dat <- array(dim=c(n_files, 12), dimnames = NULL)
n_files <- 10
dat <- array(dim=c(n_files, 12), dimnames = NULL)
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source('C:/Users/jgaci/Google Drive/2016_Fall/Applied_Data_Science/Project03/Fall2016-proj3-grp6/main_base.R', echo=TRUE)
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source('C:/Users/jgaci/Google Drive/2016_Fall/Applied_Data_Science/Project03/Fall2016-proj3-grp6/main_base.R', echo=TRUE)
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
View(dat_train_RGB)
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source('C:/Users/jgaci/Google Drive/2016_Fall/Applied_Data_Science/Project03/Fall2016-proj3-grp6/main_base.R', echo=TRUE)
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
View(dat_train_RGB)
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
library(EBImage)
library(fitdistrplus)
library(mixtools)
dog.file <- "dog_1000.jpg"
chicken.file <- "chicken_0001.jpg"
img.dog <- readImage(paste0("./data/images/",dog.file))
img.chicken <- readImage(paste0("./data/images/",chicken.file))
img.dog
img.dog$dim
img.dog
img.dog$w
img.dog
nrow(img.dog)
ncol(img.dog)
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
library(EBImage)
library(fitdistrplus)
library(mixtools)
dog.file <- "dog_1000.jpg"
chicken.file <- "chicken_0001.jpg"
img.dog <- readImage(paste0("./data/images/",dog.file))
img.chicken <- readImage(paste0("./data/images/",chicken.file))
hist(img.chicken, main = chicken.file)
hist(img.dog, main = dog.file)
chicken.file <- "chicken_0049.jpg"
img.chicken <- readImage(paste0("./data/images/",chicken.file))
red.channel <- as.vector(as.array(img.chicken[,,1]))
hist(red.channel)
hist(channel)
channel <- as.vector(as.array(img.chicken[,,1]))
hist(channel)
for(i in 1:3){
channel <- as.vector(as.array(img.chicken[,,i]))
hist(channel)
}
#############################################
### Main execution script for experiments ###
#############################################
### Author: Yuting Ma
### Project 3
### ADS Spring 2016
### Specify directories
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
img_train_dir <- "./data/images/"
#img_test_dir <- "./data/zipcode_test/"
### Import training images class labels ----
#label_train <- read.table("./data/zip_train_label.txt", header=F)
#label_train <- as.numeric(unlist(label_train) == "9")
num_chicken <- 1000
num_dog <- 1000
label_train <- c(rep(0, num_chicken), rep(1, num_dog))
### Construct visual feature ----
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
### Construct visual feature ----
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
source("./lib/feature.R")
tm_feature_train_RGB <- system.time(dat_train_RGB <- feature_RGB("./data/images/", "RGB"))
file <- "dog_0997.jpg"
img.file <- readImage(paste0("./data/images/",file))
for(i in 1:3){
channel <- as.vector(as.array(img.file[,,i]))
hist(channel)
}
for(i in 1:3){
channel <- as.vector(as.array(img.file[,,i]))
channel <- channel[channel < 0.99]
hist(channel)
}
for(i in 1:3){
channel <- as.vector(as.array(img.file[,,i]))
channel <- channel[channel < 0.98]
hist(channel)
}
for(i in 1:3){
channel <- as.vector(as.array(img.file[,,i]))
channel <- channel[channel < 0.95]
hist(channel)
}
